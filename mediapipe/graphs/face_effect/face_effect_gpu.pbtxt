# MediaPipe graph that applies a face effect to the input video stream.

# GPU buffer. (GpuBuffer)
input_stream: "input_video"

# A list of geometry data for a single detected face.
#
# NOTE: there will not be an output packet in this stream for this particular
# timestamp if none of faces detected.
#
# (std::vector<face_geometry::FaceGeometry>)
output_stream: "multi_face_geometry"

# Landmark presence (needed because whole graph won't emit anything if no faces are detected)
output_stream: "landmark_presence"

# Generates an environment that describes the current virtual scene.
node {
  calculator: "FaceGeometryEnvGeneratorCalculator"
  output_side_packet: "ENVIRONMENT:environment"
  node_options: {
    [type.googleapis.com/mediapipe.FaceGeometryEnvGeneratorCalculatorOptions] {
      environment: {
        origin_point_location: TOP_LEFT_CORNER 
        perspective_camera: {
          vertical_fov_degrees: 63.0  # 63 degrees
          near: 1.0  # 1cm
          far: 10000.0  # 100m
        }
      }
    }
  }
}

node {
  calculator: "SingleFaceGeometryFromLandmarksGpu"
  input_stream: "IMAGE:throttled_input_video"
  input_side_packet: "ENVIRONMENT:environment"
  output_stream: "MULTI_FACE_GEOMETRY:multi_face_geometry"
}

node {
  calculator: "FlowLimiterCalculator"
  input_stream: "input_video"
  input_stream: "FINISHED:multi_face_geometry"
  input_stream_info: {
    tag_index: "FINISHED"
    back_edge: true
  }
  output_stream: "throttled_input_video"
}

# See this thread here https://github.com/google/mediapipe/issues/850#issuecomment-683268033
# "if there are no packets in the corresponding output stream, it is designed to wait until the packet comes in"
# That means that we'd get absolutely nothing to work with and won't know if our frame had anythin!
# So we add PacketPresenceCalculator
node {
  calculator: "PacketPresenceCalculator"
  input_stream: "PACKET:multi_face_geometry"
  output_stream: "PRESENCE:landmark_presence"
}
